{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bingo Tutorial 5: Benchmarking Symbolic Regression\n",
    "\n",
    "## Goal: Compare the performance of two optimization approaches on a set of symbolic regression benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks in Bingo\n",
    "\n",
    "There are several symbolic regression benchmarks included within Bingo.  These benchmarks can be used to compare the effect of different evolutionary approaches.  \n",
    "Every benchmark in Bingo contains information about the benchmark (e.g., name, descritpion, source) as well as training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bingo.symbolic_regression.benchmarking.benchmark_definitions import bench_koza_1\n",
    "\n",
    "koza_benchmark = bench_koza_1()\n",
    "print(\"Benchmark Name:\", koza_benchmark.name)\n",
    "print(\"Description:\", koza_benchmark.description)\n",
    "print(\"Source:\", koza_benchmark.source)\n",
    "\n",
    "plt.plot(koza_benchmark.training_data.x, koza_benchmark.training_data.y, \n",
    "         'b.', label='training_data')\n",
    "plt.plot(koza_benchmark.test_data.x, koza_benchmark.test_data.y, \n",
    "         'r.', label='training_data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Suites\n",
    "\n",
    "In Bingo a `BenchmarkSuite` is a collection of benchmarks that allows for easy filtering of all the included benchmarks and automatic testing of an evolutionary strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.symbolic_regression.benchmarking.benchmark_suite import BenchmarkSuite\n",
    "\n",
    "suite = BenchmarkSuite(inclusive_terms=[\"Koza\"])\n",
    "\n",
    "for benchmark in suite:\n",
    "    print(benchmark.name, \"\\t\", benchmark.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark tests\n",
    "\n",
    "In order to take advantage of the automatic testing of a evolutionary strategy.  The strategy and desired scoring must be defined in the form of a `BenchmarkTest`.  \n",
    "\n",
    "The benchmark test uses two functions to define its behavior.  The first defines the evolutionary strategy, i.e., how to get the best individual as a function of the training data.  The example given here uses an evolutionary optimization very similar to the one in Tutorial 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.symbolic_regression.agraph.component_generator import ComponentGenerator\n",
    "from bingo.symbolic_regression.agraph.generator import AGraphGenerator\n",
    "from bingo.symbolic_regression.agraph.crossover import AGraphCrossover\n",
    "from bingo.symbolic_regression.agraph.mutation import AGraphMutation\n",
    "from bingo.symbolic_regression.explicit_regression import ExplicitRegression\n",
    "from bingo.local_optimizers.continuous_local_opt import ContinuousLocalOptimization\n",
    "from bingo.evaluation.evaluation import Evaluation\n",
    "from bingo.evolutionary_algorithms.age_fitness import AgeFitnessEA\n",
    "from bingo.evolutionary_optimizers.island import Island\n",
    "\n",
    "def training_function_af(training_data):\n",
    "    component_generator = ComponentGenerator(input_x_dimension=training_data.x.shape[1])\n",
    "    component_generator.add_operator(\"+\")\n",
    "    component_generator.add_operator(\"-\")\n",
    "    component_generator.add_operator(\"*\")\n",
    "\n",
    "    agraph_generator = AGraphGenerator(agraph_size=16, \n",
    "                                       component_generator=component_generator)\n",
    "\n",
    "    crossover = AGraphCrossover()\n",
    "    mutation = AGraphMutation(component_generator)\n",
    "\n",
    "    fitness = ExplicitRegression(training_data=training_data)\n",
    "    local_opt_fitness = ContinuousLocalOptimization(fitness, algorithm='lm')\n",
    "    evaluator = Evaluation(local_opt_fitness)\n",
    "\n",
    "    POPULATION_SIZE = 32\n",
    "    MUTATION_PROBABILITY = 0.4\n",
    "    CROSSOVER_PROBABILITY = 0.4\n",
    "\n",
    "    ea = AgeFitnessEA(evaluator, agraph_generator, crossover, mutation, \n",
    "                      MUTATION_PROBABILITY, CROSSOVER_PROBABILITY, POPULATION_SIZE)\n",
    "\n",
    "\n",
    "    island = Island(ea, agraph_generator, POPULATION_SIZE)\n",
    "\n",
    "    opt_result = island.evolve_until_convergence(max_generations=300,\n",
    "                                                 fitness_threshold=1e-6)\n",
    "\n",
    "    return island.get_best_individual(), opt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function is a function that will be used to score how well an the strategy performed.  In the example used here, we are scoring the strategy based on fitness (mean absolute error) and sucessful convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_function(equation, scoring_data, opt_result):\n",
    "    mae_function = ExplicitRegression(training_data=scoring_data)\n",
    "    mae = mae_function(equation)\n",
    "    return mae, opt_result.success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the above two functions gives the `BenchmarkTest` which can be used by the `BenchmarkSuite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.symbolic_regression.benchmarking.benchmark_test import BenchmarkTest\n",
    "\n",
    "age_fitness_strategy = BenchmarkTest(training_function_af, scoring_function)\n",
    "train_scores_af, test_scores_af = suite.run_benchmark_test(age_fitness_strategy,\n",
    "                                                           repeats=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores for the benchmarks on both their training and test datasets are the result.  One set of scores is given for each of the 4 repeats so that statistical measures can be used for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "mae_test_af = []\n",
    "mae_train_af = []\n",
    "success_rate_af = []\n",
    "for train, test in zip(train_scores_af, test_scores_af):\n",
    "    avg_train = np.mean(np.array(train), axis=0)\n",
    "    avg_test = np.mean(np.array(test), axis=0)\n",
    "    mae_train_af.append(avg_train[0])\n",
    "    success_rate_af.append(avg_train[1])\n",
    "    mae_test_af.append(avg_test[0])\n",
    "    \n",
    "labels = [bench.name for bench in suite]\n",
    "label_locations = np.arange(len(labels))\n",
    "bar_width = 0.35\n",
    "_ = ax1.bar(label_locations - bar_width/2, mae_train_af, bar_width, label='Train')\n",
    "_ = ax1.bar(label_locations + bar_width/2, mae_test_af, bar_width, label='Test')\n",
    "_ = ax2.bar(label_locations, success_rate_af, bar_width*2)\n",
    "\n",
    "ax1.set_ylabel('Average Mean Absolute Error')\n",
    "ax1.set_xticks(label_locations)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.legend()\n",
    "ax2.set_ylabel('Success Rate')\n",
    "ax2.set_xticks(label_locations)\n",
    "ax2.set_xticklabels(labels)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to another strategy\n",
    "\n",
    "By creating a new training function and rerunning the benchmarks, we can compare the above evolutionary strategy (which uses age-fitness EA) to one  that uses deterministic crowding. \n",
    "\n",
    "Note that only the EA portion of the following function is different than the training function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bingo.evolutionary_algorithms.deterministic_crowding import DeterministicCrowdingEA\n",
    "\n",
    "def training_function_dc(training_data):\n",
    "    component_generator = ComponentGenerator(input_x_dimension=training_data.x.shape[1])\n",
    "    component_generator.add_operator(\"+\")\n",
    "    component_generator.add_operator(\"-\")\n",
    "    component_generator.add_operator(\"*\")\n",
    "\n",
    "    agraph_generator = AGraphGenerator(agraph_size=16, \n",
    "                                       component_generator=component_generator)\n",
    "\n",
    "    crossover = AGraphCrossover()\n",
    "    mutation = AGraphMutation(component_generator)\n",
    "\n",
    "    fitness = ExplicitRegression(training_data=training_data)\n",
    "    local_opt_fitness = ContinuousLocalOptimization(fitness, algorithm='lm')\n",
    "    evaluator = Evaluation(local_opt_fitness)\n",
    "\n",
    "    POPULATION_SIZE = 32\n",
    "    MUTATION_PROBABILITY = 0.4\n",
    "    CROSSOVER_PROBABILITY = 0.4\n",
    "\n",
    "    ea = DeterministicCrowdingEA(evaluator, crossover, mutation, \n",
    "                                 MUTATION_PROBABILITY, CROSSOVER_PROBABILITY)\n",
    "\n",
    "\n",
    "    island = Island(ea, agraph_generator, POPULATION_SIZE)\n",
    "\n",
    "    opt_result = island.evolve_until_convergence(max_generations=300,\n",
    "                                                 fitness_threshold=1e-6)\n",
    "\n",
    "    return island.get_best_individual(), opt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now rerun the benchmark suite with the new strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deterministic_crowding_strategy = BenchmarkTest(training_function_dc, scoring_function)\n",
    "train_scores_dc, test_scores_dc = suite.run_benchmark_test(deterministic_crowding_strategy,\n",
    "                                                           repeats=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(8, 4.5))\n",
    "\n",
    "mae_test_dc = []\n",
    "mae_train_dc = []\n",
    "success_rate_dc = []\n",
    "for train, test in zip(train_scores_dc, test_scores_dc):\n",
    "    avg_train = np.mean(np.array(train), axis=0)\n",
    "    avg_test = np.mean(np.array(test), axis=0)\n",
    "    mae_train_dc.append(avg_train[0])\n",
    "    success_rate_dc.append(avg_train[1])\n",
    "    mae_test_dc.append(avg_test[0])\n",
    "    \n",
    "labels = [bench.name for bench in suite]\n",
    "label_locations = np.arange(len(labels))\n",
    "bar_width = 0.35\n",
    "_ = ax1.bar(label_locations - bar_width/2, mae_train_af, bar_width, label='AF')\n",
    "_ = ax1.bar(label_locations + bar_width/2, mae_train_dc, bar_width, label='DC')\n",
    "\n",
    "_ = ax2.bar(label_locations - bar_width/2, mae_test_af, bar_width)\n",
    "_ = ax2.bar(label_locations + bar_width/2, mae_test_dc, bar_width)\n",
    "\n",
    "_ = ax3.bar(label_locations - bar_width/2, success_rate_af, bar_width)\n",
    "_ = ax3.bar(label_locations + bar_width/2, success_rate_dc, bar_width)\n",
    "\n",
    "ax1.set_ylabel('Average Mean Absolute Error (Train)')\n",
    "ax1.set_xticks(label_locations)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.legend()\n",
    "ax2.set_ylabel('Average Mean Absolute Error (Test)')\n",
    "ax2.set_xticks(label_locations)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax3.set_ylabel('Success Rate')\n",
    "ax3.set_xticks(label_locations)\n",
    "ax3.set_xticklabels(labels)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
